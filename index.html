<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
    <!-- ***** -->
    <title>
        k* Distribution: Evaluating the Latent Space of Deep Neural Networks using Local Neighborhood Analysis
    </title>
    <meta name="description"
        content="Project page for &#39;k* Distribution: Evaluating the Latent Space of Deep Neural Networks using Local Neighborhood Analysis.&#39;">
    <!-- ***** -->

    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <style>
        @import url('https://fonts.cdnfonts.com/css/chalkduster');
    </style>

    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="style.css" type="text/css">
    <link rel="stylesheet" href="https://fonts.cdnfonts.com/css/chalkduster" >
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous">

</head>

<body>

    <p class="title">
        k* Distribution: Evaluating the Latent Space of Deep Neural Networks using Local Neighborhood Analysis
    </p>

    <div style="text-align: center; font-size: 40pt; margin-bottom: 30px">
            <!-- <span>CVPR 2023</span> -->
    </div>

    <p class="author">
        <span class="author"><a target="_blank" href="https://sites.google.com/site/shashankkotyan">Shashank&nbsp;Kotyan</a>&nbsp;<sup>*</sup></span>
        <span class="author">Ueda&nbsp;Tatsuya&nbsp;<sup>*</sup></span>
        <span class="author"><a target="_blank" href="http://danilovargas.org/">Danilo&nbsp;Vasconcellos&nbsp;Vargas</a></span>
    </p>

    <table class="affiliations">
        <tbody>
            <tr>
                <td style="text-align: center; width:0%; ">Kyushu University</td>
            </tr>
            <tr>
                <td style="text-align: center; width:0%; "><sup>*</sup>&nbsp;Equal Contribution</td>
            </tr>
        </tbody>
    </table>

    <table align="center" class="menu">
        <tbody>
            <tr>
                <td align="center"> 
                    <span class="menu"><a href="https://ieeexplore.ieee.org/document/10680459" target="_blank">[Paper]</a></span>
                    <span class="menu"><a href="https://arxiv.org/abs/2312.04024" target="_blank">[PrePrint]</a></span>
                    <span class="menu"><a href="https://github.com/shashankkotyan/k-Distribution/blob/main/code/k-Distribution.ipynb">[Code]</a></span>
                    <span class="menu"><a href="./assets/reference.bib">[BibTeX]</a></span>
                </td> 
            </tr>
        </tbody>
    </table>

    <div class="container">
        <br><hr class="hr-twill-colorful"><br>

        <div class="image" style="text-align:center;">
            <img src="./assets/illustration.png" alt="Overview of three distinct basic patterns of k* Distribution." width="60%" style="margin: auto" />
            <figcaption>Figure: Overview of three distinct basic patterns of k* Distribution.</figcaption>
        </div>
        
        <br>

        <strong>Key Contributions:</strong>

        <ul>
            <li> Identification of various distribution patterns of samples in the latent space based on neighborhood characteristics </li>
            <li> A model-agnostic latent space analysis of neural networks, focusing on samples from a single class </li>
            <li> A method for straightforwardly comparing different classes and understanding how samples from various classes are distributed in the learned latent space </li>
        </ul>

        <br><hr class="hr-twill-colorful"><br>

        <p class="section"><strong>Abstract</strong></p> 
        <p class="text"> 
            Most examinations of neural networks' learned latent spaces typically employ dimensionality reduction techniques such as t-SNE or UMAP.
            While these methods effectively capture the overall sample distribution in the entire learned latent space, they tend to distort the structure of sample distributions within specific classes in the subset of the latent space.
            This distortion complicates the task of easily distinguishing classes identifiable by neural networks.
            In response to this challenge, we introduce the k* Distribution methodology.
            This approach focuses on capturing the characteristics and structure of sample distributions for individual classes within the subset of the learned latent space using local neighborhood analysis.
            The key concept is to facilitate easy comparison of different k* distributions, enabling analysis of how various classes are processed by the same neural network.
            This provides a more profound understanding of existing contemporary visualizations.
            Our study reveals three distinct distributions of samples within the learned latent space subset:
            a) Fractured, b) Overlapped, and c) Clustered.
            We note and demonstrate that the distribution of samples within the network's learned latent space significantly varies depending on the class.
            Furthermore, we illustrate that our analysis can be applied to explore the latent space of
            diverse neural network architectures,
            various layers within neural networks,
            transformations applied to input samples,
            and the distribution of training and testing data
            for neural networks.
            We anticipate that our approach will facilitate more targeted investigations into neural networks by collectively examining the distribution of different samples within the learned latent space.
        </p>    

        <br><hr class="hr-twill-colorful"><br>

        <p class="section"><strong>Method</strong></p>

        <div class="image">
            <img src="./assets/framework.png" alt="" width="100%"/>
            <figcaption class="caption">Figure: Overview of the framework to create k* Distribution. We use the learned features of a neural network to compute k* values of individual evaluated sample and then compute the k* distribution for a particular class.</figcaption>
        </div>
        <br>
        <div class="image">
            <img src="./assets/explanation.png" alt="" width="100%" style="margin: auto" />
            <figcaption>Figure: Illustration of calculating k* value of a sample and correspondingly k* distribution of class. </figcaption>
        </div>
        

        <br><hr class="hr-twill-colorful"><br>

        <p class="section"><strong>Visualizations of Latent Space</strong></p>

        <p class="subsection" style="text-align:justify">

            <hr>
            
            <button type="button" class="accordion-button" data-bs-toggle="collapse" data-bs-target="#collapseOne" ><strong>I. Comparison with different architectures </strong></button>
            <div id="collapseOne" class="content collapse">
                <br>

                <p style="text-align: center">
                    <strong>ResNet-50</strong>
                </p>
                <div class="image">
                    <img src="./assets/ResNet-IN-IN_16-Base-Test-distribution-1.png" alt="" width="33%">
                    <img src="./assets/ResNet-IN-IN_16-Base-Test-distribution-2.png" alt="" width="33%">
                    <img src="./assets/ResNet-IN-IN_16-Base-Test-dr.png" alt="" width="33%">
                    <figcaption> Figure: Visualization of the distribution of samples in latent space using, k* distribution, and Dimensionality Reduction techniques like t-SNE, Isomap, PCA, and UMAP of all classes of 16-class-ImageNet for the Logit Layer of ResNet-50 Architecture.</figcaption> 
                </div>

                <br><br>
                <p style="text-align: center">
                    <strong>ResNeXt-101</strong>
                </p>
                <div class="image">
                    <img src="./assets/ResNeXt-IN-IN_16-Base-Test-distribution-1.png" alt="" width="33%">
                    <img src="./assets/ResNeXt-IN-IN_16-Base-Test-distribution-2.png" alt="" width="33%">
                    <img src="./assets/ResNeXt-IN-IN_16-Base-Test-dr.png" alt="" width="33%">
                    <figcaption> Figure: Visualization of the distribution of samples in latent space using, k* distribution, and Dimensionality Reduction techniques like t-SNE, Isomap, PCA, and UMAP of all classes of 16-class-ImageNet for the Logit Layer of ResNet-50 Architecture.</figcaption> 
                </div>
                
                <br><br>
                <p style="text-align: center">
                    <strong>EfficientNet-B0</strong>
                </p>
                <div class="image">
                    <img src="./assets/EfficientNet-IN-IN_16-Base-Test-distribution-1.png" alt="" width="33%">
                    <img src="./assets/EfficientNet-IN-IN_16-Base-Test-distribution-2.png" alt="" width="33%">
                    <img src="./assets/EfficientNet-IN-IN_16-Base-Test-dr.png" alt="" width="33%">
                    <figcaption> Figure: Visualization of the distribution of samples in latent space using, k* distribution, and Dimensionality Reduction techniques like t-SNE, Isomap, PCA, and UMAP of all classes of 16-class-ImageNet for the Logit Layer of ResNet-50 Architecture.</figcaption> 
                </div>
                
                <br><br>
                <p style="text-align: center">
                    <strong>ViT-Base</strong>
                </p>
                <div class="image">
                    <img src="./assets/ViT-B-IN-IN_16-Base-Test-distribution-1.png" alt="" width="33%">
                    <img src="./assets/ViT-B-IN-IN_16-Base-Test-distribution-2.png" alt="" width="33%">
                    <img src="./assets/ViT-B-IN-IN_16-Base-Test-dr.png" alt="" width="33%">
                    <figcaption> Figure: Visualization of the distribution of samples in latent space using, k* distribution, and Dimensionality Reduction techniques like t-SNE, Isomap, PCA, and UMAP of all classes of 16-class-ImageNet for the Logit Layer of ResNet-50 Architecture.</figcaption> 
                </div>
            </div>

            <hr>

            <button type="button" class="accordion-button" data-bs-toggle="collapse" data-bs-target="#collapseTwo" ><strong>II. Comparison with different layers of neural network </strong></button>
            <div id="collapseTwo" class="content collapse">
                <br>
                <p style="text-align: center">
                    <strong>Logit Layer of ResNet-50</strong>
                </p>
                
                <div class="image">
                    <img src="./assets/ResNet-IN-IN_16-Base-Test-distribution-1.png" alt="" width="33%">
                    <img src="./assets/ResNet-IN-IN_16-Base-Test-distribution-2.png" alt="" width="33%">
                    <img src="./assets/ResNet-IN-IN_16-Base-Test-dr.png" alt="" width="33%">
                    <figcaption> Figure: Visualization of the distribution of samples in latent space using, k* distribution, and Dimensionality Reduction techniques like t-SNE, Isomap, PCA, and UMAP of all classes of 16-class-ImageNet for the Logit Layer of ResNet-50 Architecture.</figcaption> 
                </div>

                <br><br>
                <p style="text-align: center">
                    <strong>Average Pooling Layer of ResNet-50</strong>
                </p>

                <div class="image">
                    <img src="./assets/ResNet-IN-IN_16-Base-Test-avgpool-distribution-1.png" alt="" width="33%">
                    <img src="./assets/ResNet-IN-IN_16-Base-Test-avgpool-distribution-2.png" alt="" width="33%">
                    <img src="./assets/ResNet-IN-IN_16-Base-Test-avgpool-dr.png" alt="" width="33%">
                    <figcaption> Figure: Visualization of the distribution of samples in latent space using, k* distribution, and Dimensionality Reduction techniques like t-SNE, Isomap, PCA, and UMAP of all classes of 16-class-ImageNet for the Logit Layer of ResNet-50 Architecture.</figcaption> 
                </div>
            </div>

            <hr>
            
            <button type="button" class="accordion-button" data-bs-toggle="collapse" data-bs-target="#collapseThree" ><strong>III. Comparison with different training distributions </strong></button>
            <div id="collapseThree" class="content collapse">
                <br>
                <p style="text-align: center">
                    <strong>ResNet-50 Trained with ImageNet-1k</strong>
                </p>
                
                <div class="image">
                    <img src="./assets/ResNet-IN-IN_16-Base-Test-distribution-1.png" alt="" width="33%">
                    <img src="./assets/ResNet-IN-IN_16-Base-Test-distribution-2.png" alt="" width="33%">
                    <img src="./assets/ResNet-IN-IN_16-Base-Test-dr.png" alt="" width="33%">
                    <figcaption> Figure: Visualization of the distribution of samples in latent space using, k* distribution, and Dimensionality Reduction techniques like t-SNE, Isomap, PCA, and UMAP of all classes of 16-class-ImageNet for the Logit Layer of ResNet-50 Architecture.</figcaption> 
                </div>

                <br><br>
                <p style="text-align: center">
                    <strong>ResNet-50 Trained with Stylized ImageNet-1k</strong>
                </p>

                <div class="image">
                    <img src="./assets/ResNet-SIN-IN_16-Base-Test-distribution-1.png" alt="" width="33%">
                    <img src="./assets/ResNet-SIN-IN_16-Base-Test-distribution-2.png" alt="" width="33%">
                    <img src="./assets/ResNet-SIN-IN_16-Base-Test-dr.png" alt="" width="33%">
                    <figcaption> Figure: Visualization of the distribution of samples in latent space using, k* distribution, and Dimensionality Reduction techniques like t-SNE, Isomap, PCA, and UMAP of all classes of 16-class-ImageNet for the Logit Layer of ResNet-50 Architecture.</figcaption> 
                </div>
                
                <br><br>
                <p style="text-align: center">
                    <strong>ResNet-50 Trained with ImageNet1k + Stylized ImageNet-1k</strong>
                </p>

                <div class="image">
                    <img src="./assets/ResNet-SIN_IN-IN_16-Base-Test-distribution-1.png" alt="" width="33%">
                    <img src="./assets/ResNet-SIN_IN-IN_16-Base-Test-distribution-2.png" alt="" width="33%">
                    <img src="./assets/ResNet-SIN_IN-IN_16-Base-Test-dr.png" alt="" width="33%">
                    <figcaption> Figure: Visualization of the distribution of samples in latent space using, k* distribution, and Dimensionality Reduction techniques like t-SNE, Isomap, PCA, and UMAP of all classes of 16-class-ImageNet for the Logit Layer of ResNet-50 Architecture.</figcaption> 
                </div>
            </div>

            <hr>
            
            <button type="button" class="accordion-button" data-bs-toggle="collapse" data-bs-target="#collapseFour" ><strong>III. Comparison with adversarially trained networks </strong></button>
            <div id="collapseFour" class="content collapse">
                <br>
                <p style="text-align: center">
                    <strong>ResNet-50 without Adversarial Training</strong>
                </p>
                
                <div class="image">
                    <img src="./assets/ResNet-IN-IN_16-Base-Test-distribution-1.png" alt="" width="33%">
                    <img src="./assets/ResNet-IN-IN_16-Base-Test-distribution-2.png" alt="" width="33%">
                    <img src="./assets/ResNet-IN-IN_16-Base-Test-dr.png" alt="" width="33%">
                    <figcaption> Figure: Visualization of the distribution of samples in latent space using, k* distribution, and Dimensionality Reduction techniques like t-SNE, Isomap, PCA, and UMAP of all classes of 16-class-ImageNet for the Logit Layer of ResNet-50 Architecture.</figcaption> 
                </div>

                <br><br>
                <p style="text-align: center">
                    <strong>ResNet-50 with Adversarial Training</strong>
                </p>

                <div class="image">
                    <img src="./assets/pgd_resnet50_at_clean_eps4_IN_16-distribution-1.png" alt="" width="33%">
                    <img src="./assets/pgd_resnet50_at_clean_eps4_IN_16-distribution-2.png" alt="" width="33%">
                    <img src="./assets/pgd_resnet50_at_clean_eps4_IN_16-dr.png" alt="" width="33%">
                    <figcaption> Figure: Visualization of the distribution of samples in latent space using, k* distribution, and Dimensionality Reduction techniques like t-SNE, Isomap, PCA, and UMAP of all classes of 16-class-ImageNet for the Logit Layer of ResNet-50 Architecture.</figcaption> 
                </div>
            </div>
            
        </p>

        <br><hr class="hr-twill-colorful"><br>

        <p class="section" id="bibtex"><b>Bibtex</b></p>
        <pre class="bibtex">
@article{kotyan2024kdistribution,
  title={{{k* Distribution}}: Evaluating the {{Latent Space}} of {{Deep Neural Networks}} Using {{Local Neighborhood Analysis}}},
  shorttitle = {{{k* Distribution}}},
  author={Kotyan, Shashank and Ueda, Tatsuya and Vargas, Danilo Vasconcellos},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2024},
  publisher={IEEE}
}
        </pre>

    </div>



</body>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.6/dist/umd/popper.min.js" integrity="sha384-oBqDVmMz9ATKxIep9tiCxS/Z9fNfEXiDAYTujMAeBAsjFuCZSmKbSSUnQlmh/jp3" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-kenU1KFdBIe4zVF0s0G1M5b4hcpxyD9F7jL+jjXkk+Q2h455rYXK/7HAuoJl+0I4" crossorigin="anonymous"></script>
</html>
